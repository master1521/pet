{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d489bf7f-bd03-4fdc-affd-8d2805d34a6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "                # НАСТРОЙКА"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "fa6cfbec-5ff3-4d06-8c86-61f04830db24",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:__main__:Spark version: 3.5.0\n",
      "INFO:__main__:Default catalog: iceberg\n",
      "INFO:__main__:REST Catalog: http://iceberg-rest:8181\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "import os\n",
    "import logging\n",
    "\n",
    "logging.basicConfig(level=logging.INFO)\n",
    "logger = logging.getLogger(__name__)\n",
    "\n",
    "def create_spark_session() -> SparkSession:\n",
    "    \"\"\"\n",
    "    Создать Spark сессию с Iceberg REST Catalog и MinIO.\n",
    "    Credentials берутся из переменных окружения.\n",
    "    \n",
    "    Returns:\n",
    "        SparkSession: Настроенная сессия\n",
    "    \"\"\"\n",
    "    \n",
    "    access_key = os.environ.get('AWS_ACCESS_KEY_ID', 'admin')\n",
    "    secret_key = os.environ.get('AWS_SECRET_ACCESS_KEY', 'password')\n",
    "    \n",
    "    spark = SparkSession.builder \\\n",
    "        .appName(\"Iceberg-Basics\") \\\n",
    "        .config(\"spark.sql.catalog.iceberg\", \"org.apache.iceberg.spark.SparkCatalog\") \\\n",
    "        .config(\"spark.sql.catalog.iceberg.type\", \"rest\") \\\n",
    "        .config(\"spark.sql.catalog.iceberg.uri\", \"http://iceberg-rest:8181\") \\\n",
    "        .config(\"spark.sql.catalog.iceberg.io-impl\", \"org.apache.iceberg.aws.s3.S3FileIO\") \\\n",
    "        .config(\"spark.sql.catalog.iceberg.warehouse\", \"s3://warehouse\") \\\n",
    "        .config(\"spark.sql.catalog.iceberg.s3.endpoint\", \"http://minio:9000\") \\\n",
    "        .config(\"spark.sql.catalog.iceberg.s3.access-key-id\", access_key) \\\n",
    "        .config(\"spark.sql.catalog.iceberg.s3.secret-access-key\", secret_key) \\\n",
    "        .config(\"spark.sql.catalog.iceberg.s3.path-style-access\", \"true\") \\\n",
    "        .config(\"spark.sql.defaultCatalog\", \"iceberg\") \\\n",
    "        .config(\"spark.sql.extensions\", \"org.apache.iceberg.spark.extensions.IcebergSparkSessionExtensions\") \\\n",
    "        .getOrCreate()\n",
    "    \n",
    "    logger.info(f\"Spark version: {spark.version}\")\n",
    "    logger.info(f\"Default catalog: iceberg\")\n",
    "    logger.info(f\"REST Catalog: http://iceberg-rest:8181\")\n",
    "    \n",
    "    return spark\n",
    "\n",
    "spark = create_spark_session()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78c5c563-2b59-4e05-bd87-68d5244904b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "def check_environment_variables() -> None:\n",
    "    \"\"\"Проверить переменные окружения.\"\"\"\n",
    "    \n",
    "    print(\"=\" * 80)\n",
    "    print(\"ПЕРЕМЕННЫЕ ОКРУЖЕНИЯ\")\n",
    "    print(\"=\" * 80)\n",
    "    \n",
    "    env_vars = [\n",
    "        'SPARK_HOME',\n",
    "        'JAVA_HOME',\n",
    "        'PATH',\n",
    "        'PYTHONPATH',\n",
    "        'SPARK_DRIVER_MEMORY',\n",
    "        'SPARK_EXECUTOR_MEMORY',\n",
    "        'PYSPARK_PYTHON',\n",
    "        'PYSPARK_DRIVER_PYTHON'\n",
    "    ]\n",
    "    \n",
    "    for var_name in env_vars:\n",
    "        var_value = os.environ.get(var_name, 'НЕ УСТАНОВЛЕНА')\n",
    "        print(f\"{var_name}: {var_value}\")\n",
    "    \n",
    "    print(\"=\" * 80)\n",
    "check_environment_variables()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed35d764-5f4c-4c6c-8ccb-ba0deac28363",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "def check_spark_config() -> None:\n",
    "    \"\"\"Проверить spark-defaults.conf файл.\"\"\"\n",
    "    \n",
    "    spark_home = os.environ.get('SPARK_HOME')\n",
    "    print(\"\\n\" + \"=\" * 80)\n",
    "    print(\"SPARK CONFIGURATION (spark-defaults.conf)\")\n",
    "    print(\"=\" * 80)\n",
    "    \n",
    "    if not spark_home:\n",
    "        print(\"SPARK_HOME: НЕ УСТАНОВЛЕН\")\n",
    "        print(\"=\" * 80)\n",
    "        return\n",
    "    \n",
    "    config_path = f\"{spark_home}/conf/spark-defaults.conf\"\n",
    "    print(f\"Путь к файлу: {config_path}\")\n",
    "    print(\"-\" * 80)\n",
    "    \n",
    "    if os.path.exists(config_path):\n",
    "        with open(config_path, 'r') as f:\n",
    "            lines = f.readlines()\n",
    "        \n",
    "        if lines:\n",
    "            for line in lines:\n",
    "                line = line.strip()\n",
    "                if line and not line.startswith('#'):\n",
    "                    print(line)\n",
    "        else:\n",
    "            print(\"Статус: ФАЙЛ ПУСТОЙ\")\n",
    "    else:\n",
    "        print(\"Статус: ФАЙЛ НЕ НАЙДЕН\")\n",
    "    \n",
    "    print(\"=\" * 80)\n",
    "check_spark_config()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0c078b2-586e-49f4-8d64-1a12b14e2640",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import glob\n",
    "\n",
    "def check_spark_jars() -> None:\n",
    "    \"\"\"Проверить JAR файлы в Spark.\"\"\"\n",
    "    \n",
    "    spark_home = os.environ.get('SPARK_HOME')\n",
    "    \n",
    "    print(\"\\n\" + \"=\" * 80)\n",
    "    print(\"JAR ФАЙЛЫ В SPARK\")\n",
    "    print(\"=\" * 80)\n",
    "    \n",
    "    if not spark_home:\n",
    "        print(\"SPARK_HOME: НЕ УСТАНОВЛЕН\")\n",
    "        print(\"=\" * 80)\n",
    "        return\n",
    "    \n",
    "    jars_dir = f\"{spark_home}/jars\"\n",
    "    print(f\"Директория JAR: {jars_dir}\")\n",
    "    print(\"-\" * 80)\n",
    "    \n",
    "    if not os.path.exists(jars_dir):\n",
    "        print(f\"Статус: ДИРЕКТОРИЯ НЕ НАЙДЕНА\")\n",
    "        print(\"=\" * 80)\n",
    "        return\n",
    "    \n",
    "    # Критичные JAR для Iceberg\n",
    "    jar_patterns = {\n",
    "        'iceberg-spark-runtime': '*iceberg-spark-runtime*.jar',\n",
    "        'iceberg-aws-bundle': '*iceberg-aws-bundle*.jar',\n",
    "        'hadoop-aws': '*hadoop-aws*.jar',\n",
    "        'aws-java-sdk-bundle': '*aws-java-sdk-bundle*.jar',\n",
    "        'postgresql': '*postgresql*.jar'\n",
    "    }\n",
    "    \n",
    "    for jar_name, pattern in jar_patterns.items():\n",
    "        jars = glob.glob(f\"{jars_dir}/{pattern}\")\n",
    "        \n",
    "        if jars:\n",
    "            for jar_path in jars:\n",
    "                filename = os.path.basename(jar_path)\n",
    "                size_mb = os.path.getsize(jar_path) / (1024 * 1024)\n",
    "                print(f\"{jar_name}: {filename} ({size_mb:.2f} MB)\")\n",
    "        else:\n",
    "            print(f\"{jar_name}: НЕ НАЙДЕН\")\n",
    "    \n",
    "    print(\"-\" * 80)\n",
    "    \n",
    "    # Подсчет всех JAR\n",
    "    all_jars = glob.glob(f\"{jars_dir}/*.jar\")\n",
    "    print(f\"Всего JAR файлов: {len(all_jars)}\")\n",
    "    print(\"=\" * 80)\n",
    "\n",
    "check_spark_jars()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2629cd0b-60dc-4222-90b9-ff74095f59e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import subprocess\n",
    "from typing import Dict, Optional\n",
    "\n",
    "def get_package_version(package_name: str) -> Optional[str]:\n",
    "    \"\"\"\n",
    "    Получить версию установленного пакета.\n",
    "    \n",
    "    Args:\n",
    "        package_name: Название пакета\n",
    "        \n",
    "    Returns:\n",
    "        Версия пакета или None если не установлен\n",
    "    \"\"\"\n",
    "    result = subprocess.run(\n",
    "        ['pip', 'show', package_name],\n",
    "        capture_output=True,\n",
    "        text=True\n",
    "    )\n",
    "    \n",
    "    if result.returncode == 0:\n",
    "        for line in result.stdout.split('\\n'):\n",
    "            if line.startswith('Version:'):\n",
    "                return line.split(':', 1)[1].strip()\n",
    "    return None\n",
    "\n",
    "def check_python_packages() -> None:\n",
    "    \"\"\"Проверить установленные Python пакеты.\"\"\"\n",
    "    \n",
    "    print(\"\\n\" + \"=\" * 80)\n",
    "    print(\"PYTHON ПАКЕТЫ\")\n",
    "    print(\"=\" * 80)\n",
    "    \n",
    "    packages = [\n",
    "        'pyspark',\n",
    "        'pyiceberg',\n",
    "        'delta-spark',\n",
    "        'great-expectations',\n",
    "        'py4j',\n",
    "        'pandas',\n",
    "        'numpy'\n",
    "    ]\n",
    "    \n",
    "    for package in packages:\n",
    "        version = get_package_version(package)\n",
    "        status = version if version else 'НЕ УСТАНОВЛЕН'\n",
    "        print(f\"{package}: {status}\")\n",
    "    \n",
    "    print(\"=\" * 80)\n",
    "\n",
    "check_python_packages()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "139b6c36-c7b8-424e-9967-6358c5ea83cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "                # ПОЛУЧИТЬ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2f1b0af4-bcb6-4fc9-ae32-f449d41fd08f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+\n",
      "|namespace|\n",
      "+---------+\n",
      "|  sandbox|\n",
      "+---------+\n",
      "\n",
      "+---------+---------+-----------+\n",
      "|namespace|tableName|isTemporary|\n",
      "+---------+---------+-----------+\n",
      "|  sandbox|   orders|      false|\n",
      "|  sandbox| products|      false|\n",
      "|  sandbox|    users|      false|\n",
      "+---------+---------+-----------+\n",
      "\n",
      "+----------------------------+----------------------------+-------+\n",
      "|col_name                    |data_type                   |comment|\n",
      "+----------------------------+----------------------------+-------+\n",
      "|user_id                     |bigint                      |NULL   |\n",
      "|name                        |string                      |NULL   |\n",
      "|email                       |string                      |NULL   |\n",
      "|age                         |bigint                      |NULL   |\n",
      "|country                     |string                      |NULL   |\n",
      "|is_active                   |boolean                     |NULL   |\n",
      "|created_at                  |timestamp_ntz               |NULL   |\n",
      "|                            |                            |       |\n",
      "|# Metadata Columns          |                            |       |\n",
      "|_spec_id                    |int                         |       |\n",
      "|_partition                  |struct<>                    |       |\n",
      "|_file                       |string                      |       |\n",
      "|_pos                        |bigint                      |       |\n",
      "|_deleted                    |boolean                     |       |\n",
      "|                            |                            |       |\n",
      "|# Detailed Table Information|                            |       |\n",
      "|Name                        |iceberg.sandbox.users       |       |\n",
      "|Type                        |MANAGED                     |       |\n",
      "|Location                    |s3://warehouse/sandbox/users|       |\n",
      "|Provider                    |iceberg                     |       |\n",
      "+----------------------------+----------------------------+-------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Просмотр namespaces, таблиц и описать таблицу \n",
    "spark.sql(\"SHOW NAMESPACES IN iceberg\").show()\n",
    "spark.sql(\"SHOW TABLES IN iceberg.sandbox\").show()\n",
    "spark.sql(\"DESCRIBE EXTENDED sandbox.users\").show(truncate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90191292-ebb5-4b53-9d4d-abb755180406",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Чтение из таблицы users\n",
    "# Запросы можно делать к iceberg.sandbox.users или к sandbox.users\n",
    "users_df = spark.sql(\"\"\"\n",
    "    SELECT * \n",
    "    FROM iceberg.sandbox.users\n",
    "    LIMIT 10 \"\"\")\n",
    "users_df.show()\n",
    "# users_df.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8c39faf-abbd-4a9c-99ec-4dd125635425",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Чтение из таблицы products\n",
    "spark.sql(\"SELECT * FROM sandbox.products\").show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "835536ca-21e9-4db9-9306-5cf45d1dd5b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Чтение из таблицы orders\n",
    "spark.sql(\"SELECT * FROM sandbox.orders\").show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1704c37-c53c-4f81-91f3-57aeb2619cd4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b840a8a-2b9d-4661-8d0f-59fddfa0c82b",
   "metadata": {},
   "outputs": [],
   "source": [
    "                # СОЗДАТЬ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef0318f7-bd18-4b61-859b-93c2213c2cbb",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Через генератор тестовых данных CreateTestData.py создал структуру Iceberg Data Lakehouse из трех таблиц в s3\n",
    "- sandbox.users Пользователи\n",
    "- sandbox.orders Заказы\n",
    "- sandbox.products Товары \n",
    "Описание структуры таблиц и данных смотреть в CreateTestData.py в этом блакноте изучем работу с Iceberg через Spark SQL и Spark DataFrame API \n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c27f5db0-71eb-4ae0-8749-0ff71882811f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Создать namespace'ы\n",
    "spark.sql(\"CREATE NAMESPACE IF NOT EXISTS sandbox\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d65031da-6352-4640-aab2-0a361df36de3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f20f465-692d-4b13-b04a-176047c5ab57",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Создаем новую независимую таблицу для практики Spark SQL\n",
    "# customer_reviews (отзывы клиентов) Эта таблица будет связана с существующими, но не изменит их структуру.\n",
    "\"\"\"\n",
    "Блок TBLPROPERTIES при создании таблицы задаёт свойства Iceberg, которые управляют хранилищем и форматами данных:\n",
    "\"\"\"\n",
    "\n",
    "# Создать таблицу\n",
    "spark.sql(\"\"\"\n",
    "    CREATE TABLE IF NOT EXISTS sandbox.customer_reviews (\n",
    "        review_id BIGINT,\n",
    "        user_id BIGINT,\n",
    "        product_id BIGINT,\n",
    "        order_id BIGINT,\n",
    "        rating INT,\n",
    "        review_text STRING,\n",
    "        helpful_count INT,\n",
    "        verified_purchase BOOLEAN,\n",
    "        review_date TIMESTAMP,\n",
    "        created_at TIMESTAMP\n",
    "    )\n",
    "    USING iceberg\n",
    "    PARTITIONED BY (months(review_date))\n",
    "    TBLPROPERTIES (\n",
    "        'write.format.default' = 'parquet',\n",
    "        'write.metadata.compression-codec' = 'gzip',\n",
    "        'format-version' = '2'\n",
    "    )\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7be8ca0b-d45d-4d8b-91cf-c63d269b9591",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Проверить создание\n",
    "spark.sql(\"DESCRIBE EXTENDED sandbox.customer_reviews\").show(truncate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d73f962a-44c1-439b-9a4b-334031c6fbc7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1934eaa1-5d36-405b-9bd1-aeb5de2fcda1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Генерация тестовых данных для customer_reviews"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6eaee8e0-6f77-4e84-b3f3-6918bfa34145",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import functions as F\n",
    "from datetime import datetime, timedelta\n",
    "import random\n",
    "\n",
    "# Прочитать существующие таблицы\n",
    "orders_df = spark.table(\"iceberg.sandbox.orders\")\n",
    "\n",
    "# Генерация: ~30% заказов имеют отзывы\n",
    "reviews_sample = orders_df.sample(0.3)\n",
    "\n",
    "# Создать отзывы\n",
    "reviews_df = reviews_sample \\\n",
    "    .select(\n",
    "        F.monotonically_increasing_id().alias(\"review_id\"),\n",
    "        F.col(\"user_id\"),\n",
    "        F.col(\"product_id\"),\n",
    "        F.col(\"order_id\"),\n",
    "        F.round(F.rand() * 4 + 1).cast(\"int\").alias(\"rating\"),\n",
    "        F.concat(\n",
    "            F.lit(\"Great product \"),\n",
    "            F.col(\"product_id\").cast(\"string\")\n",
    "        ).alias(\"review_text\"),\n",
    "        F.round(F.rand() * 50).cast(\"int\").alias(\"helpful_count\"),\n",
    "        F.when(F.col(\"status\") == \"completed\", True).otherwise(False).alias(\"verified_purchase\"),\n",
    "        (F.col(\"order_date\") + F.expr(\"INTERVAL 3 DAYS\")).alias(\"review_date\"),\n",
    "        F.current_timestamp().alias(\"created_at\")\n",
    "    )\n",
    "\n",
    "# Показать preview\n",
    "print(f\"Всего отзывов: {reviews_df.count()}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a9a4025-0281-4abb-b16d-b2e99f6859b0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6294f978-c68c-481a-8f60-46be9fd7ebd3",
   "metadata": {},
   "outputs": [],
   "source": [
    "                # ЗАГРУЗИТЬ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9780c883-52a4-4956-9990-c1e217a46dba",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Вариант А: через DataFrame API\n",
    "reviews_df.writeTo(\"sandbox.customer_reviews\") \\\n",
    "    .using(\"iceberg\") \\\n",
    "    .append()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c770ce9-7586-4f6e-8031-983d29e4eaeb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Вариант Б: через SQL\n",
    "# reviews_df.createOrReplaceTempView(\"temp_reviews\")\n",
    "\n",
    "# spark.sql(\"\"\"\n",
    "#     INSERT INTO sandbox.customer_reviews\n",
    "#     SELECT * FROM temp_reviews\n",
    "# \"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a0093c4-98ad-4c6c-9ea9-3c16af68c8fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Проверить\n",
    "spark.sql(\"SELECT COUNT(*) as total FROM sandbox.customer_reviews\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2c57569-1932-4e02-aa31-0b107ad7dc6f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b33da233-f89d-455d-8a02-db932a2cb1e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "                # ОБНОВИТЬ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1177498-a53c-4445-9cad-51c3b7928009",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-27T11:30:11.378978Z",
     "start_time": "2025-11-27T11:30:11.281835Z"
    }
   },
   "outputs": [],
   "source": [
    "# Обновить helpful_count для отзывов с высоким рейтингом\n",
    "spark.sql(\"\"\"\n",
    "    UPDATE sandbox.customer_reviews\n",
    "    SET helpful_count = helpful_count + 10\n",
    "    WHERE rating >= 4\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2eab712a-b987-4d9e-ad70-3f0218e60676",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Проверить\n",
    "spark.sql(\"\"\"\n",
    "    SELECT rating, AVG(helpful_count) as avg_helpful\n",
    "    FROM iceberg.sandbox.customer_reviews\n",
    "    GROUP BY rating\n",
    "    ORDER BY rating\n",
    "\"\"\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ee48098-9080-4a4c-86da-137a8e8cfed5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04e90e4c-37be-487e-b689-dc31596e188c",
   "metadata": {},
   "outputs": [],
   "source": [
    "                # УДАЛИТЬ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f5ec1b6-2c75-4828-9432-071e963bc6c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Удалить таблицу customer_reviews\n",
    "\"\"\"\n",
    "DROP TABLE (без PURGE):\n",
    "Файлы остаются в S3 (безопасность от случайного удаления)\n",
    "Удаляет метаданные таблицы в REST‑каталоге;\n",
    "\"\"\"\n",
    "\n",
    "spark.sql(\"DROP TABLE IF EXISTS sandbox.customer_reviews\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf1c0b4a-8cc0-4636-8d76-0dedbc09bc1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Проверить что удалилась\n",
    "spark.sql(\"SHOW TABLES IN iceberg.sandbox\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9072b1f2-7721-49e0-8950-d55ceb875f5a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "430d9fa3-9d9d-45b4-b574-e453e01ed33a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Удалить таблицу И файлы из S3\n",
    "\"\"\"\n",
    "DROP TABLE PURGE:\n",
    "Удаляет метаданные\n",
    "Удаляет все файлы из S3\n",
    "Используй PURGE для полной очистки!\n",
    "\n",
    "Iceberg REST catalog - PURGE может не удалять данные сразу из-за асинхронности или прав доступа.\n",
    "Iceberg удаляет файлы окончательно через процедуры обслуживания, а не моментально при DROP.\n",
    "\"\"\"\n",
    "spark.sql(\"DROP TABLE IF EXISTS sandbox.customer_reviews PURGE\")\n",
    "\n",
    "# Проверить что удалилась\n",
    "spark.sql(\"SHOW TABLES IN iceberg.sandbox\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da153ed0-a8ac-484e-82a8-b9f3dd64a8fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Удалить отзывы без подтверждения покупки и с низким рейтингом\n",
    "spark.sql(\"\"\"\n",
    "    DELETE FROM sandbox.customer_reviews\n",
    "    WHERE verified_purchase = false \n",
    "      AND rating <= 2\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc8e8ac0-5de3-41c8-98a5-57d8b6d9c8bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Показать сколько удалили\n",
    "spark.sql(\"\"\"\n",
    "    SELECT \n",
    "        COUNT(*) as total_reviews,\n",
    "        SUM(CASE WHEN verified_purchase = false THEN 1 ELSE 0 END) as unverified\n",
    "    FROM sandbox.customer_reviews\n",
    "\"\"\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4830247-9fa7-47ef-96e3-090262068a3a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48c8d217-4242-4d37-86e0-d29fd9746563",
   "metadata": {},
   "outputs": [],
   "source": [
    "                # АНАЛИТИЧЕСКИЕ ЗАПРОСЫ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b874bd7a-678c-4be7-9861-b4a7b6b4463a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+-----+------------------+\n",
      "|rating|  cnt|       avg_helpful|\n",
      "+------+-----+------------------+\n",
      "|     1|   54| 55.48148148148148|\n",
      "|     2|  915| 48.78251366120219|\n",
      "|     3| 6028|50.233742534837425|\n",
      "|     4|10536| 49.82232346241458|\n",
      "|     5|11819| 51.95989508418648|\n",
      "+------+-----+------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Проверка распределения\n",
    "spark.sql(\"\"\"\n",
    "  SELECT \n",
    "      rating, \n",
    "      COUNT(*) AS cnt, \n",
    "      AVG(helpful_count) AS avg_helpful\n",
    "  FROM sandbox.customer_reviews\n",
    "  GROUP BY rating\n",
    "  ORDER BY rating\n",
    "\"\"\").show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "589a7367-e7d3-4ff6-bf5c-d4be8bfd71ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Получить статистику по странам\n",
    "spark.sql(\"\"\"\n",
    "    SELECT \n",
    "        country,\n",
    "        COUNT(*) as users_count,\n",
    "        AVG(age) as avg_age\n",
    "    FROM iceberg.sandbox.users\n",
    "    GROUP BY country\n",
    "    ORDER BY users_count DESC\n",
    "\"\"\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f4844cc7-cac1-4fd6-a4fc-34f9f9c8f549",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+-------------------+-------------------+\n",
      "| cnt|             min_dt|             max_dt|\n",
      "+----+-------------------+-------------------+\n",
      "|5470|2024-05-01 00:00:00|2024-05-31 00:00:00|\n",
      "+----+-------------------+-------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Чтение с фильтром по месяцу (partition pruning)\n",
    "spark.sql(\"\"\"\n",
    "  SELECT \n",
    "    COUNT(*) AS cnt,\n",
    "    MIN(review_date) AS min_dt,\n",
    "    MAX(review_date) AS max_dt\n",
    "  FROM sandbox.customer_reviews\n",
    "  WHERE review_date >= '2024-05-01' AND review_date < '2024-06-01'\n",
    "\"\"\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "737c6308-7048-4214-b8c5-f539cb31c735",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec31fe40-39f7-4143-bb72-db16146b56ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Средний рейтинг по категориям товаров\n",
    "spark.sql(\"\"\"\n",
    "    SELECT \n",
    "        p.category,\n",
    "        COUNT(r.review_id) as reviews_count,\n",
    "        AVG(r.rating) as avg_rating,\n",
    "        SUM(r.helpful_count) as total_helpful\n",
    "    FROM sandbox.customer_reviews r\n",
    "    JOIN sandbox.products p ON r.product_id = p.product_id\n",
    "    GROUP BY p.category\n",
    "    ORDER BY avg_rating DESC\n",
    "\"\"\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0352296b-c061-4fdf-8fd0-717a7a30611f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Топ товары по отзывам\n",
    "spark.sql(\"\"\"\n",
    "    SELECT \n",
    "        p.product_name,\n",
    "        p.category,\n",
    "        COUNT(r.review_id) as reviews_count,\n",
    "        AVG(r.rating) as avg_rating\n",
    "    FROM sandbox.customer_reviews r\n",
    "    JOIN sandbox.products p ON r.product_id = p.product_id\n",
    "    GROUP BY p.product_name, p.category\n",
    "    HAVING COUNT(r.review_id) >= 5\n",
    "    ORDER BY avg_rating DESC, reviews_count DESC\n",
    "    LIMIT 10\n",
    "\"\"\").show(truncate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55619446-3ffa-4746-9192-e73c77da2bb0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Активные рецензенты\n",
    "spark.sql(\"\"\"\n",
    "    SELECT \n",
    "        u.name,\n",
    "        u.country,\n",
    "        COUNT(r.review_id) as reviews_written,\n",
    "        AVG(r.rating) as avg_rating_given\n",
    "    FROM sandbox.customer_reviews r\n",
    "    JOIN sandbox.users u ON r.user_id = u.user_id\n",
    "    GROUP BY u.name, u.country\n",
    "    ORDER BY reviews_written DESC\n",
    "    LIMIT 10\n",
    "\"\"\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f3720d3-964d-4816-94fa-cb7c215c19e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Создать агрегированную таблицу средних рейтингов по категориям\n",
    "# CREATE TABLE AS SELECT\n",
    "spark.sql(\"\"\"\n",
    "  CREATE TABLE IF NOT EXISTS sandbox.category_ratings\n",
    "  USING iceberg\n",
    "  TBLPROPERTIES (\n",
    "    'write.format.default' = 'parquet',\n",
    "    'write.metadata.compression-codec' = 'gzip',\n",
    "    'format-version' = '2'\n",
    "  )\n",
    "  AS\n",
    "  SELECT \n",
    "    p.category,\n",
    "    COUNT(r.review_id) AS reviews_count,\n",
    "    AVG(r.rating) AS avg_rating,\n",
    "    SUM(r.helpful_count) AS total_helpful\n",
    "  FROM sandbox.customer_reviews r\n",
    "  JOIN sandbox.products p ON r.product_id = p.product_id\n",
    "  GROUP BY p.category\n",
    "\"\"\")\n",
    "\n",
    "# Проверка\n",
    "spark.sql(\"SELECT * FROM sandbox.category_ratings\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2283aaa-35a7-450c-8660-012c826eb75b",
   "metadata": {},
   "outputs": [],
   "source": [
    "                # МЕТАДАННЫЕ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3512b32-44b4-49a4-9f60-b7850635875f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eea7d906-8759-4a39-a012-a8b3681dcdba",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def show_properties(table_name: str) -> None:\n",
    "    \"\"\"Показать свойства таблицы Iceberg.\"\"\"\n",
    "    spark.sql(f\"SHOW TBLPROPERTIES {table_name}\").show(truncate=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "083203ab-b95e-4872-8736-a3ec1cffe331",
   "metadata": {},
   "outputs": [],
   "source": [
    "show_properties(\"sandbox.customer_reviews\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28bab55a-538c-4da2-b61b-c9169cc2e155",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1aaf6629-7e30-4015-acb6-4bb8061745e8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
