# ===== ПОДКЛЮЧЕНИЕ К КЛАСТЕРУ =====
# URL мастера кластера (применяется только при запуске через spark-submit)
spark.master                     spark://spark-master:7077


# ===== СЕРИАЛИЗАЦИЯ =====
# Kryo сериализатор быстрее стандартного Java на 10x, меньше размер данных при shuffle
spark.serializer                 org.apache.spark.serializer.KryoSerializer


# ===== ADAPTIVE QUERY EXECUTION (AQE) =====
# Автоматическая оптимизация плана выполнения SQL запросов в runtime
spark.sql.adaptive.enabled       true

# Автоматическое объединение мелких партиций после shuffle для уменьшения overhead
spark.sql.adaptive.coalescePartitions.enabled true

# Автоматическое определение skewed данных в join и оптимизация через репартиционирование
spark.sql.adaptive.skewJoin.enabled true


# ===== УПРАВЛЕНИЕ ПАМЯТЬЮ =====
# 60% heap памяти выделяется для execution и storage, остальное для внутренних структур Spark
spark.memory.fraction            0.6

# Из memory.fraction 50% для хранения кэша (storage), 50% для вычислений (execution)
spark.memory.storageFraction     0.5


# ===== SHUFFLE ОПТИМИЗАЦИЯ =====
# Количество партиций по умолчанию после shuffle операций (join, groupBy, agg)
# 200 подходит для средних датасетов, для больших увеличивай до 1000-2000
spark.sql.shuffle.partitions     200

# Уровень параллелизма для RDD операций (map, filter, flatMap)
# Должен быть = количество ядер на всех воркерах (у тебя 2*2=4)
spark.default.parallelism        4

# Внешний shuffle service отключен (нужен для dynamic allocation, который не используется)
spark.shuffle.service.enabled    false


# ===== UI И МОНИТОРИНГ =====
# Включить веб-интерфейс Spark UI для мониторинга задач
spark.ui.enabled                 true

# Порт для Spark Application UI (драйвер)
spark.ui.port                    4040

# Сохранение истории выполнения задач в файлы (отключено для локального кластера)
spark.eventLog.enabled           false


# ===== BROADCAST JOIN =====
# Таблицы меньше 10MB автоматически broadcast на все ноды для join (ускоряет join)
# Увеличивай если есть таблицы-справочники больше 10MB
spark.sql.autoBroadcastJoinThreshold 10485760

# ===== COMPRESSION =====
# Алгоритм сжатия для shuffle данных (snappy быстрый, zstd лучше компрессия)
spark.io.compression.codec       snappy

# Сжимать RDD при сериализации (экономит память, но добавляет CPU overhead)
spark.rdd.compress               true


# ===== ДРАЙВЕР (добавь для твоего кластера) =====
# Память для драйвера (увеличивай если используешь collect(), toPandas(), broadcast больших данных)
spark.driver.memory              2g

# Количество ядер для драйвера
spark.driver.cores               2


# ===== EXECUTOR (добавь для контроля ресурсов) =====
# Память для каждого executor на воркерах
spark.executor.memory            2g

# Количество ядер для каждого executor
spark.executor.cores             2


# ===== ДИНАМИЧЕСКОЕ ВЫДЕЛЕНИЕ РЕСУРСОВ =====
# Отключено, так как не используется external shuffle service
spark.dynamicAllocation.enabled  false


# ===== СЕТЕВЫЕ НАСТРОЙКИ =====
# Таймаут сетевых операций между нодами (увеличивай если видишь timeout ошибки)
spark.network.timeout            120s

# Таймаут для RPC запросов между драйвером и executor
spark.rpc.askTimeout             120s


